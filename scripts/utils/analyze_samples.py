#!/usr/bin/env python3
"""
åˆ†æ Word æ–‡ä»¶ç¤ºèŒƒçš„è„šæœ¬
ç”¨äºäº†è§£ç›‘ç£é€šçŸ¥ä¹¦çš„å…·ä½“æ ¼å¼å’Œç»“æ„
"""

import os
from pathlib import Path

# å°è¯•å¯¼å…¥ python-docxï¼Œå¦‚æœæ²¡æœ‰åˆ™æç¤ºå®‰è£…
try:
    from docx import Document
    from docx.table import Table
except ImportError:
    print("è¯·å…ˆå®‰è£… python-docx: pip install python-docx")
    exit(1)


def analyze_word_file(file_path):
    """åˆ†æ Word æ–‡ä»¶çš„ç»“æ„"""
    print(f"\n{'='*80}")
    print(f"åˆ†ææ–‡ä»¶: {file_path}")
    print(f"{'='*80}\n")
    
    try:
        doc = Document(file_path)
    except Exception as e:
        print(f"âŒ æ— æ³•æ‰“å¼€æ–‡ä»¶: {e}")
        return
    
    # 1. åˆ†ææ®µè½
    print("ğŸ“„ æ®µè½å†…å®¹:")
    print("-" * 80)
    for i, para in enumerate(doc.paragraphs[:20]):  # åªæ˜¾ç¤ºå‰20ä¸ªæ®µè½
        text = para.text.strip()
        if text:
            print(f"  [{i}] {text[:100]}")
    
    if len(doc.paragraphs) > 20:
        print(f"  ... è¿˜æœ‰ {len(doc.paragraphs) - 20} ä¸ªæ®µè½")
    
    # 2. åˆ†æè¡¨æ ¼
    print(f"\nğŸ“Š è¡¨æ ¼æ•°é‡: {len(doc.tables)}")
    print("-" * 80)
    
    for table_idx, table in enumerate(doc.tables):
        print(f"\n  è¡¨æ ¼ {table_idx + 1}:")
        print(f"    è¡Œæ•°: {len(table.rows)}, åˆ—æ•°: {len(table.columns)}")
        
        # æ˜¾ç¤ºè¡¨æ ¼å‰å‡ è¡Œ
        for row_idx, row in enumerate(table.rows[:5]):
            cells_text = [cell.text.strip()[:20] for cell in row.cells]
            print(f"    è¡Œ {row_idx}: {cells_text}")
        
        if len(table.rows) > 5:
            print(f"    ... è¿˜æœ‰ {len(table.rows) - 5} è¡Œ")
    
    # 3. åˆ†æå›¾ç‰‡
    print(f"\nğŸ–¼ï¸  å›¾ç‰‡æ•°é‡: {count_images(doc)}")
    print("-" * 80)
    
    # 4. åˆ†ææ–‡æœ¬ç‰¹å¾
    print(f"\nğŸ” æ–‡æœ¬ç‰¹å¾åˆ†æ:")
    print("-" * 80)
    full_text = "\n".join([para.text for para in doc.paragraphs])
    
    # æŸ¥æ‰¾å…³é”®å­—æ®µ
    keywords = [
        "é¡¹ç›®åç§°", "æ ‡æ®µ", "å·¥ç‚¹", "å»ºè®¾å•ä½", "æ–½å·¥å•ä½", 
        "ç›‘ç†å•ä½", "æ£€æŸ¥æ—¶é—´", "æ£€æŸ¥äººå‘˜", "é—®é¢˜", "æ•´æ”¹"
    ]
    
    for keyword in keywords:
        if keyword in full_text:
            print(f"  âœ… æ‰¾åˆ°å…³é”®å­—: {keyword}")
        else:
            print(f"  âŒ æœªæ‰¾åˆ°å…³é”®å­—: {keyword}")
    
    # 5. ç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯:")
    print("-" * 80)
    print(f"  æ€»æ®µè½æ•°: {len(doc.paragraphs)}")
    print(f"  æ€»è¡¨æ ¼æ•°: {len(doc.tables)}")
    print(f"  æ€»æ–‡æœ¬é•¿åº¦: {len(full_text)} å­—ç¬¦")
    print(f"  æ€»è¡Œæ•°: {len(full_text.split(chr(10)))}")


def count_images(doc):
    """è®¡ç®—æ–‡æ¡£ä¸­çš„å›¾ç‰‡æ•°é‡"""
    count = 0
    for rel in doc.part.rels.values():
        if "image" in rel.target_ref:
            count += 1
    return count


def main():
    """ä¸»å‡½æ•°"""
    samples_dir = Path("Samples")
    
    if not samples_dir.exists():
        print(f"âŒ æ‰¾ä¸åˆ° Samples ç›®å½•")
        return
    
    # æŸ¥æ‰¾æ‰€æœ‰ .docx æ–‡ä»¶
    docx_files = list(samples_dir.glob("*.docx"))
    
    if not docx_files:
        print(f"âŒ åœ¨ Samples ç›®å½•ä¸­æ‰¾ä¸åˆ° .docx æ–‡ä»¶")
        return
    
    print(f"\nğŸ” æ‰¾åˆ° {len(docx_files)} ä¸ª Word æ–‡ä»¶")
    
    for file_path in docx_files:
        analyze_word_file(str(file_path))
    
    print(f"\n{'='*80}")
    print("âœ… åˆ†æå®Œæˆ")
    print(f"{'='*80}\n")


if __name__ == "__main__":
    main()

